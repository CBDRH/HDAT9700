<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="false" />
<meta name="allow-skip" content="true" />

<title>HDAT9700: Directed Acyclic Graphs (DAGs)</title>


<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>

<!-- taken from https://github.com/rstudio/rmarkdown/blob/67b7f5fc779e4cfdfd0f021d3d7745b6b6e17149/inst/rmd/h/default.html#L296-L362 -->
<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>
<!-- end tabsets -->


<link rel="stylesheet" href="css/tutorials.css" type="text/css" />

</head>

<body>



<div class="pageContent band">
<div class="bandContent page">

<div class="topics">

<p><img src="images/UNSW_2017_Big_Data_landscape.jpg" style="width:75.0%" /></p>
<div id="section-useful-links" class="section level2">
<h2>Useful links</h2>
<p><a href="http://www.dagitty.net/learn/graphs/table2-fallacy.html" class="uri">http://www.dagitty.net/learn/graphs/table2-fallacy.html</a> <a href="http://www.dagitty.net/learn/graphs/roles.html" class="uri">http://www.dagitty.net/learn/graphs/roles.html</a></p>
<p>Game on terminology <a href="http://www.dagitty.net/learn/graphs/index.html" class="uri">http://www.dagitty.net/learn/graphs/index.html</a></p>
</div>
<div id="section-notes-from-the-harvardx-course" class="section level2">
<h2>Notes from the Harvardx course</h2>
<p>"This introductory course to causal diagrams teaches you how to translate expert knowledge into a causal diagrams. By the end of the course you will be able:</p>
<p>To draw causal diagrams under different assumptions To identify common biases using causal diagrams To guide data analysis using causal diagrams"</p>
<p>Babies example - Babies born to mothers who smoked are more likely to die - BUT among low weight babies, those whose mothers smoked are less likely to die</p>
<ul>
<li>"Use simple pictures tho think about causal questions</li>
<li>Ok answer comes later!</li>
</ul>
<p>Correlation versus causation Counderfactuals “Quantifying casual effects requires the comparison of the same or similar treatments” “there may be association without causation” “casusal diagrams represent association and causation simultaneously”</p>
<p>The first lesson of the course introduces you to causal diagrams. You will learn the anatomy of a DAG and the rules of D-separation.</p>
<p>Learning Objectives After this lesson you should be able to:</p>
<ol style="list-style-type: decimal">
<li><p>Identify the features of a causal DAG</p></li>
<li><p>Understand the rules of d-separation</p></li>
<li><p>Construct a causal DAG that reflects assumptions of how treatments, outcomes, and other factors relate to one another</p></li>
<li><p>Distinguish between different structural sources of bias</p></li>
</ol>
<p>Estrogen and uterine cancer problem - Assocaition between estrogen and endometrial cancer observed - Estrogen use causes uterine bleeding so women went to Drs to investigate, leading to more diagnoses of otherwise unobserved cancers - ’Referred to as ascertainment bias" - What about restricting to women who bleed?</p>
<p>Causal diagrams - Nodes connected by arrows (or directed edges) - It is acyclic (can’t go in cycles) - Time goes from left to right; the future can’t affect the past - Causal Markov condition (all common causes included) - A square box representes conditioning - DAG for RCT rather than DAG for retrospective cohort study - DAGs represent causal graphs and statistical models - “Casusal graphs do not need to include mediators to estimate the effect of A on Y”</p>
<p>Example: smoking, yellow fingers and lung cancer - A shared common cause between A and Y leads us to expect an association between A and Y, even if A does not cause Y - e.g. there will be an assocation between yellow fingers and cancer, but no yellow fingers does not cause cancer - The flow of association between A and Y is blocked when we condition on a common cause L.</p>
<p>Colliders - Common effects - Common effects of A and Y will not induce an association - Conditioning on a common effect of A and Y will induce an asscoiation between A and Y - This is known as selection bias - Similarly, conditioning on something affected by a collider will induce an association between A and Y</p>
<p>Structural sources of association - cause and effect - common causes - conditioning on common effects Other important source of association, but not structural - Chance</p>
<p>Causal graph theory - Descendents (child/grandchild/parent/grandparent)</p>
<p>D (direction) seperation Rules</p>
<p>"Two variables are D-seperated if all paths between them have been blocked</p>
<ol style="list-style-type: decimal">
<li><p>“If there are no variables being conditioned on, a path is blocked if and only if two arrowheads on the path collide at some variable on the path.”</p></li>
<li><p>“Any path that contains a noncollider that has been conditioned on is blocked”</p></li>
<li><p>“A collider that has been conditioned on does not block a path.”</p></li>
<li><p>“A collider that has a descendant that has been conditioned on does not block a path.”</p></li>
</ol>
<p>Faithfulness - If the effect of A and Y is opposite in the population it could be the case that although A causes Y, there is no association between A and Y - “Then we say that the joint distribution of the data is not faithful to the casual DAG”</p>
<p>Confounding Common causes of exposure and outcome result in confounding bias</p>
<p>Confounding is the bias Counfounders are variables used to block the backdoor path(s)</p>
<p>Backdoor path The backdoor path between a hypotesised cause (A) and outcome (Y) is a path that connects A and Y without using any of the arrows that leave from Y.</p>
<p>Backdoor path criterion We can estimate the causal effect of A on Y if we can block all the backdoor path</p>
<p>“To deal with confounding we need to use expert knowledge”</p>
<p>M-bias</p>
<p>Sometimes we won’t have the observed confounder so we can use surrogate or proxy confounders</p>
<p>Ways to control for confounding - These approachesa ssume you can measure all confounders L (not all approaches assume this e.g.) - stratification - multivariate regression - matching - matching with propensity score - inverse probability weighting - standardisation (g-formula) - g-estimation</p>
<p>“Causal DAGs allow us to identify inconsistencies between our beliefs and our actions”</p>
<p>Limitations - can’t show interactions - can’t identify whether causes only apply to some people - don’t convey numerical information</p>
</div>
<div id="section-selection-bias" class="section level2">
<h2>Selection bias</h2>
<p>Smoking and dementia example</p>
<ul>
<li>For selection to call bias it needs to be realted tot he treatment and the outcome</li>
</ul>
<p>Example of hormone therapy and cancer: - Case control studies, by design, select based on the outcome, e.g. cancer patient more likely to be selected - If there is an association between hormone therapy and selection then a bias will be introduced. - In this example, controls were selected from women in hospital for hip-fracture (can’t run away from interviewer hahaha) - But hormone therapy reduces the risk of hip-fracture, therefore there was an arrow from hormone therapy to hip fracture, and as a result an open pathway between hormone therapy and selection. - Controls were less likely to have taken hormone therapy. Therefore, even if there was no association between hip fracture and cancer, the selection would make it seem as if there is.</p>
<div id="section-follow-up-studies" class="section level3">
<h3>Follow up studies</h3>
<ul>
<li><p>Eligibility</p></li>
<li><p>Loss to folow up</p></li>
<li><p>For example of treatment for AIDS - if sicker individuals were more likely to drop out of the study, and sicker individuals were more likely to drop out of the study, this could inuduce a bias for the effect of treatment on AIDS.</p></li>
</ul>
</div>
</div>
<div id="section-overview" class="section level2">
<h2>Overview</h2>
<p>Welcome to HDAT9700 Statistical Modelling II - Causal inference and DAGs!</p>
<p>In this chapter you will start to think about how different models are used based on what sort of questions they are answering.</p>
<hr />
<div id="section-prereadings" class="section level3">
<h3>Prereadings</h3>
<p>The pre-reading for this chapter is a <em>tweetorial</em> by epidemiologist <a href="https://twitter.com/EpiEllie">Ellie Murray</a> from Boston University School of Public Health.</p>
<p>The tweetorial focuses on <strong>“the importance of being clear about your question &amp; using that to drive your methods”</strong>. Find it <a href="https://twitter.com/EpiEllie/status/1214641734900224003">here</a>.</p>
<p>Ellie’s tweetorial was prompted by a disparaging tweet about <a href="https://www.nature.com/articles/bjc2017146.pdf">this</a> study, which explores the relationship between frozen shoulder and the risk of cancer. The disparaging tweet criticised the study for failing to adjust for confounding. In her tweetorial, Ellie explains that this was a descriptive study, not one addressing a causal question and that in fact adjusting for confounding may well have led to the wrong answer to the question at hand.</p>
<p>This pre-reading should help you understand that we always need to be clear about the purpose of our models, as our purpose dictates how we specify the model.</p>
</div>
<div id="section-core-reading" class="section level3">
<h3>Core reading:</h3>
<ul>
<li><p><a href="https://doi.org/10.1080/09332480.2019.1579578">Miguel A. Hernán, John Hsu &amp; Brian Healy (2019) A Second Chance to Get Causal Inference Right: A Classification of Data Science Tasks, <em>Chance</em>, 32(1), 42-49</a></p></li>
<li><p>A paper on DAGs</p></li>
</ul>
</div>
<div id="section-additional-resources" class="section level3">
<h3>Additional resources:</h3>
<ul>
<li><p><a href="https://projecteuclid.org/euclid.ss/1294167961">Shmueli G (2010) To explain or to predict?, <em>Statistical Science</em>, 25(3), 289-310</a>. Also, if you haven’t already, check out the related <a href="https://www.youtube.com/watch?time_continue=1&amp;v=vWH_HNfQVRI&amp;vq=large">video</a>, linked at the end of the last tutorial.</p></li>
<li><p><a href="http://www.dagitty.net/learn/">dagitty.net</a>: A great website explaing DAGs and related topics, with built-in applets to test your knowledge</p></li>
<li><p>The Causal Inference Podcast, hosted by Ellie Murray and Lucy D’Agostino McGowan. Check out the first episode: <a href="https://casualinfer.libsyn.com/casual-inference-talking-target-trials-with-miguel-hernan-episode-01">Talking target trials with Miguel Hernán</a></p></li>
</ul>
</div>
</div>
<div id="section-three-tasks-of-data-science" class="section level2">
<h2>Three tasks of data science</h2>
<p>The statisical analyses you will perform as Health Data Scientists can be categorised according to three broad tasks of data science.</p>
<ol style="list-style-type: decimal">
<li>Description</li>
<li>Prediction</li>
<li>Causal inference</li>
</ol>
<p><strong>Description</strong> involves using statistical models to summarise the relationship between variables. There is no reliance on any underlying causal theory.</p>
<p><strong>Prediction</strong> involves using statistical models to predict new or future outcomes (Y) given a set of input values or variables (X).</p>
<p><strong>Causal inference</strong> involves estimating the causal effect of an exposure, treatment or intervention. Answering causal questions boils down to comparing outcomes under two or more scenarios, for example, “Would this patient have better chances of survival given treatment A or Treatment B”?</p>
<p>The table below (from <a href="https://doi.org/10.1080/09332480.2019.1579578">Hernán et al 2019</a>) provides examples of the types of questions, data and analysis methods associated with the tasks of description, prediction and causal inference.</p>
<div class="figure">
<img src="images/hernan-table1.png" style="width:100.0%" alt="" />
<p class="caption">Three tasks of data science (from Hernán et al 2019)</p>
</div>
<p><div class="panel-heading tutorial-quiz-title">Quiz: Variation across disciplines </div><div class="panel panel-default">
<div data-label="quiz1-1" class="tutorial-question panel-body">
<div id="quiz1-1-answer_container" class="shiny-html-output"></div>
<div id="quiz1-1-message_container" class="shiny-html-output"></div>
<div id="quiz1-1-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div><div class="panel panel-default">
<div data-label="quiz1-2" class="tutorial-question panel-body">
<div id="quiz1-2-answer_container" class="shiny-html-output"></div>
<div id="quiz1-2-message_container" class="shiny-html-output"></div>
<div id="quiz1-2-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div></p>
<div class="aside">
<h3 id="section-explanation-or-causal-inference">“Explanation” or “Causal Inference”?</h3>
<p>Causal inference tasks are often referred to as “Explanation” (recall the video at the end of Chapter 1 “To Explain or to Predict?” for example). However, Hernán et al (2019) emphasise that <strong>quantifying causal effects doesn’t necessarily equate to explaining causal mechanisms</strong>. This is a fair point: knowing that smoking causes cancer is different to knowing which chemicals are carcinogenic, for example.</p>
</div>
</div>
<div id="section-variable-selection" class="section level2">
<h2>Variable selection</h2>
<p>As you learned from this chapter’s pre-reading, how we go about choosing the variables to include in the model depend crucially on what we are trying to achieve.</p>
<p>For <strong>predictive</strong> models, the goal is to build a model that accurately predicts the outcome of interest with high sensitivity and specificity, and performs well on new data. In terms of variable selection, the primary consideration is choosing variables that help to achieve this goal (although you would also consider practical things like what variables will be available at the time of prediction). Variable selection could be based on univariate analysis, selecting variables that show a strong association with the outcome, or a selection algorithm like forward, backward or stepwise selection. Many machine learning algorithms will will automatically select (or appropriately weight) the most predictive variables from those available. The covariates in a predictive model all play the same role so we can refer to them collectively as <strong>predictors</strong>.</p>
<p>For <strong>causal</strong> models, the goal is to estimate the effect of a given intervention or treatment on a predefined outcome of interest. Really, the only parameter of interest from our causal model is the estimate for that intervention or treatment. In this context, other variables (that may or may not be available in your dataset) have different roles and different names which you might already have come across: <strong>confounders</strong>, <strong>mediators</strong> and <strong>colliders</strong>. Importantly, this means that <strong>just because a variable is correlated with the outcome of interest, that doesn’t necessarily mean it is a good candidate to include in the model</strong>. In order to understand what variables to include in a causal model, we need to recognise these different types of variables, and understand the role they play in the causal relationship of interest.</p>
<p>Distinguishing between confounders, mediators, colliders and other types of variables relies on expert knowledge about the subject matter in question. There is no algorithm or automated selection procedure that can replace this knowledge. Directed Acyclic Graphs, the main topic of this chapter, are an important tool that help us to formalise and graphically represent expert knowledge, and in doing so can help us to select the variables that should be included in a causal model.</p>
</div>
<div id="section-dags" class="section level2">
<h2>DAGS</h2>
<div id="section-directed-acyclic-graphs-dags" class="section level3">
<h3>Directed Acyclic Graphs (DAGs)</h3>
<p>DAGs are graphical tools used to represent the assumptions about causal relationships for a given problem. Representing these assumptions using a graph is an important approach because it allows you to</p>
<ul>
<li>Express expert knowledge explicitly</li>
<li>Facilitate discussions about variable selection with co-authors</li>
<li>Communicate your assumptions to readers</li>
</ul>
</div>
<div id="section-what-is-a-dag" class="section level3">
<h3>What is a DAG</h3>
<p>DAGs are diagrams comprising nodes (circles or squares) connected by edges (arrows). These diagrams represent assumptions about the causal relationships of interest. The nodes in a DAG represent observed or unobserved variables or constructs while the arrows indicate the direction of the causal relationship between variables.</p>
<p>In this simple DAG, the arrow points from X to Y, representing the asumption that <strong>X</strong> causes <strong>Y</strong>.</p>
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-1-1.png" width="624" /></p>
<p>The absense of an arrow between two variables represents the assumption that neither neither variable is causing or caused by the other. In the next DAG, <strong>Z</strong> causes <strong>X</strong> and <strong>Z</strong> causes <strong>Y</strong>, but <strong>X</strong> and <strong>Y</strong> are <em>causally</em> unrelated (there is no arrow pointing from <strong>X</strong> to <strong>Y</strong> or from <strong>Y</strong> to X).</p>
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-2-1.png" width="624" /></p>
<p>As we will discuss at length, the absense of an arrow between two nodes on a DAG, doesn’t mean that the variables are unassociated in an observational dataset. What if our DAG above represented <strong>sunshine</strong>, <strong>icecream sales</strong> and <strong>sunburn</strong>?</p>
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-3-1.png" width="624" /></p>
<p>We know that icecream sales definitely don’t cause sunburn, but you wouldn’t be surprised to find an association between icecream sales and incidence of sunburn (a case of correlation not implying causation!). This is a classic example of <strong>confounding bias</strong>. The relationship between icecream sales and sunburn is <strong>confounded</strong> by sunshine, inducing an association between the two variables, even though there is no causal relationship.</p>
<p>By using expert knowledge to express our qualitative understanding of causal relationships of interest, DAGs help us to distinguish between association and causation.</p>
</div>
<div id="section-properties-of-dags" class="section level3">
<h3>Properties of DAGS</h3>
<p>There are some formal requirements for a causal DAG. As indicated by the name, DAGs should be <strong>directed</strong> and <strong>acyclic</strong>.</p>
<ul>
<li><p><strong>Directed</strong> The relationship between nodes are <em>directional</em>. The arrows indicate the direction of causality.</p></li>
<li><p><strong>Acyclic</strong> DAGs must not have <em>cycles</em> between the nodes, i.e. a variable should not “cause” itself, either directly or through other variables. You can spot a cyclic relationship if it is possible to start at one node and follow the directional arrows to arrive back at the same node.</p></li>
</ul>
<p>Below is an example of a <strong>cyclic</strong> graph. The logic here is tempting: good health will improve educational outcomes, high levels of education will increase income and higher income can improve health. However this results in a cyclic graph: it is posible to start at any node and follow the directional arrows to return to that node, for example the path <strong>health</strong> <span class="math inline">\(\rightarrow\)</span> <strong>education</strong> <span class="math inline">\(\rightarrow\)</span> <strong>income</strong> <span class="math inline">\(\rightarrow\)</span> <strong>health</strong>.</p>
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-4-1.png" width="624" /></p>
<p>This would suggest that health status causes health status. Because this graph is cyclic and not acyclic, it does not meet the formal requirements for a DAG. Often, we can untangle cyclic relationships by considering the timing of causes and effects. For example, the relationship between health, education and income could be re-expressed more meaningfully by considering health status at different points in time, as represented below.</p>
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-5-1.png" width="624" /></p>
<p>This is a now valid DAG because it is <strong>directional</strong> and <strong>acyclic</strong>. Note the DAG above follows the convention that time moves from left to right.</p>
</div>
<div id="section-the-causal-markov-assumption" class="section level3">
<h3>The causal Markov assumption</h3>
<p>A further property of a causal DAG is the <strong>causal Markov assumption</strong>. Although this sounds a bit scary, it is quite simple (cf Hernán and Robins 2020 Chapter 6 Technical Point 6.1 for a formal definition). It means that a common cause of any pair of variables on a DAG should also be included in the DAG.</p>
<p>As an example, let’s say we are interested in the causal relationship between between aspirin and pulmonary embolism, in a setting where aspirin is more often prescribed to patients with high blood pressure. In this case, high blood pressure is a <strong>common cause</strong> of both aspirin usage and pulmonary embolism: patients with high blood pressure are more likely to be taking aspirin and high blood pressure increases the risk of a pulmonary embolism. To satisfy the causal Markov assumption, blood pressure should be included in the DAG.</p>
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-6-1.png" width="624" /></p>
<p>Now, imagine a different setting where aspirin has been administered as the intervention in a randomised control trial. In this case, patients are randomly assigned, so there is no causal relationship between blood pressure and taking aspirin. Blood pressure still increases the risk of having a pulmonary embolism, but it is no longer a <strong>common cause</strong> of taking aspirin and having a pulmonary embolism so it is not necessary to include on the DAG.</p>
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-7-1.png" width="624" /></p>
<hr />
</div>
<div id="section-other-terminology" class="section level3">
<h3>Other terminology</h3>
<p>Consider the DAG below which an investigator might use when postulating the causal relationship between exercise and melanoma. We will use this DAG to explain some additional useful terminology.</p>
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-8-1.png" width="624" /></p>
<div id="section-path" class="section level4">
<h4>Path</h4>
<p>A path between two nodes in a DAG is a route that connects the two nodes, visiting no node more than once. The arrows don’t have to point in the same direction, but if they do the path is considered a <em>causal path</em>.</p>
<p>Below are examples of paths:</p>
<ul>
<li>exercise <span class="math inline">\(\leftarrow\)</span> health consciousness <span class="math inline">\(\rightarrow\)</span> screening (Not a causal path)</li>
<li>health consciousness <span class="math inline">\(\rightarrow\)</span> screening <span class="math inline">\(\leftarrow\)</span> melanoma (Not a causal path)</li>
</ul>
<p>Below are examples of <strong>causal</strong> paths</p>
<ul>
<li>exercise <span class="math inline">\(\rightarrow\)</span> sun exposure <span class="math inline">\(\rightarrow\)</span> melanoma</li>
<li>sunexposure <span class="math inline">\(\rightarrow\)</span> melanoma</li>
</ul>
</div>
<div id="section-parent" class="section level4">
<h4>Parent</h4>
<p>The parents for a given node in a DAG are the set of variables with an arrow pointing directly into that node. For example, the parent of <strong>melanoma</strong> is <strong>sun exposure</strong>.</p>
</div>
<div id="section-child" class="section level4">
<h4>Child</h4>
<p>A child of a given node X is any variable with an arrow pointing directly from X. For example, <strong>exercise</strong> and <strong>screening</strong> are child nodes of <strong>health consciousness</strong>.</p>
</div>
<div id="section-descendants-and-ancestors" class="section level4">
<h4>Descendants and Ancestors</h4>
<p>The ancestors of a node are any nodes on the causal path leading to that node. The descendants of a node are any nodes that can be reached by following causal paths.</p>
<ul>
<li>The <strong>ancestors</strong> of sun exposure are exercise and health consciousness</li>
<li>The <strong>descendants</strong> of health consciousness are exercise, sun exposure, melanoma and screening</li>
</ul>
</div>
<div id="section-confounder" class="section level4">
<h4>Confounder</h4>
<p>A confounder is a <strong>common cause</strong> of two nodes (usually the common cause of an exposure and an outcome) * Health consciousness is a confounder of exercise and screening</p>
</div>
<div id="section-mediator" class="section level4">
<h4>Mediator</h4>
<p>A mediator is a node that lies on the causal path between two other nodes.</p>
<ul>
<li>Sun exposure is a mediator on the path between exercise and melanoma</li>
</ul>
</div>
<div id="section-collider" class="section level4">
<h4>Collider</h4>
<p>A collider is a node with two directional arrows pointing towards it.</p>
<ul>
<li>Screening is a collider on the path health consciousness <span class="math inline">\(\rightarrow\)</span> screening <span class="math inline">\(\leftarrow\)</span> melanoma</li>
</ul>
</div>
</div>
</div>
<div id="section-quiz" class="section level2">
<h2>Quiz</h2>
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-9-1.png" width="100%" /></p>
<p><div class="panel-heading tutorial-quiz-title">Quiz: DAGS</div><div class="panel panel-default">
<div data-label="quiz2-1" class="tutorial-question panel-body">
<div id="quiz2-1-answer_container" class="shiny-html-output"></div>
<div id="quiz2-1-message_container" class="shiny-html-output"></div>
<div id="quiz2-1-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div></p>
<hr />
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-10-1.png" width="100%" /></p>
<p><div class="panel-heading tutorial-quiz-title">Quiz: DAGS</div><div class="panel panel-default">
<div data-label="quiz3-1" class="tutorial-question panel-body">
<div id="quiz3-1-answer_container" class="shiny-html-output"></div>
<div id="quiz3-1-message_container" class="shiny-html-output"></div>
<div id="quiz3-1-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div></p>
<div id="section-want-more" class="section level4">
<h4>Want more?</h4>
<p>Try testing yourself on DAG terminology using this applet on <a href="http://www.dagitty.net/learn/graphs/index.html">dagitty.net</a>.</p>
</div>
</div>
<div id="section-confounding-variables" class="section level2">
<h2>Confounding variables</h2>
<div id="section-recall-the-definition" class="section level3">
<h3>Recall the definition</h3>
<p>Confounding arises when there is a variable <strong>Z</strong> that influences the exposure of interest <strong>X</strong> <em>and</em> the outcome of interest <strong>Y</strong>. We say that the relationship between <strong>X</strong> and <strong>Y</strong> is <em>confounded</em> and that <strong>Z</strong> is the <em>confounder</em>.</p>
<p>Depending on the discipline, confounding is also referred to as a third variable or a lurking variable.</p>
</div>
<div id="section-example" class="section level3">
<h3>Example</h3>
<p>The relationship between mother’s age at birth (exposure) and child’s birth weight (outcome) may be confounded by mother’s socioeconomic status.</p>
</div>
<div id="section-how-does-this-look-in-a-dag" class="section level3">
<h3>How does this look in a DAG?</h3>
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-11-1.png" width="624" /></p>
</div>
</div>
<div id="section-mediating-variables" class="section level2">
<h2>Mediating variables</h2>
<div id="section-definition" class="section level3">
<h3>Definition</h3>
<p>A mediating variable <strong>M</strong> is a variable that lies on the causal pathway between an exposure <strong>X</strong> and outcome <strong>Y</strong>.</p>
</div>
<div id="section-example-1" class="section level3">
<h3>Example</h3>
<p>A researcher might hypothesise that quality of sleep is a mediating variable between exercise (exposure) and mood (outcome).</p>
</div>
<div id="section-how-does-this-look-in-a-dag-1" class="section level3">
<h3>How does this look in a DAG?</h3>
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-12-1.png" width="624" /></p>
<hr />
<div class="aside">
<h3 id="section-muddling-mediation">Muddling mediation</h3>
<p>Mediation often gets confused with two closely related epidemiological concepts, <em>interaction</em> and <em>effect modification</em>. Below is a quick summary distinguishing these three terms, adapted from the paper <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5476432/">Corraini, Priscila, et al. “Effect modification, interaction and mediation: an overview of theoretical insights for clinical investigators.” Clinical epidemiology 9 (2017): 331</a></p>
<p>The table below provides a quick summary of these three concepts. If you come across these terms and need a reminder please check out the paper!</p>
</div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Type of assessment
</th>
<th style="text-align:left;">
Aim of the assessment
</th>
<th style="text-align:left;">
Example question
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Effect modification
</td>
<td style="text-align:left;">
Separate exposure effects according to another variable
</td>
<td style="text-align:left;">
Does the new drug have a different effect for men compared to women?
</td>
</tr>
<tr>
<td style="text-align:left;">
Interaction
</td>
<td style="text-align:left;">
Evaluate individual and joint effects of exposures
</td>
<td style="text-align:left;">
Does drug A work better if the patient is also taking drug B?
</td>
</tr>
<tr>
<td style="text-align:left;">
Modification
</td>
<td style="text-align:left;">
Evaluate direct and indirect effects of exposures
</td>
<td style="text-align:left;">
Does exercise improve mood directly, or does exercise improve sleep and then better sleep results in improved mood?
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="section-collider-variables" class="section level2">
<h2>Collider variables</h2>
<div id="section-definition-1" class="section level3">
<h3>Definition</h3>
<p>A collider is a common effect of two variables.</p>
</div>
<div id="section-example-2" class="section level3">
<h3>Example</h3>
<p>Suppose a researcher is interested in whether respiratory syncytial virus infection (exposure) during infancy causes asthma in early childhood (outcome). In this case, admissions to the Emergency Department (ED) during early childhood would be a potential collider, because both RSV and asthma will increase the probability of ED admission during early childhood.</p>
</div>
<div id="section-how-does-this-look-in-a-dag-2" class="section level3">
<h3>How does this look in a DAG?</h3>
<p><img src="draw-your-assumptions_files/figure-html/unnamed-chunk-14-1.png" width="624" /></p>
<p>As we will see, identifying colliders is important because controlling for a collider can introduce bias. To continue the above example, controlling for the number of ED admissions during early childhood would actually <em><strong>bias</strong></em> estimates of the relationship between RSV infection and asthma.</p>
<div class="shiny">
<h3 id="section-explore-this-further">Explore this further</h3>
<p>You can explore this example and the concept of collider bias further using this <a href="https://cbdrh.shinyapps.io/collider-bias/">interactive Shiny app</a>. The app can also be launched by entering <code>hdat9700tutorials::run('collider-bias')</code> at the console.</p>
</div>
</div>
</div>
<div id="section-d-separation" class="section level2">
<h2>D-separation</h2>
<p>Now that you know how to represent and recognise different types of relationships in a DAG, how can a DAG help us to choose what variables to include in a causal model? The answer lies in the concept of <strong>d-separation</strong>.</p>
<p><strong>Definition:</strong> Two variables in a DAG are said to be d-separated if there are no open backdoor paths between them.</p>
<p>This definition introduces two new concepts that we also have to define: <em>backdoor</em> paths, and what makes an <em>open</em> path.</p>
<div id="section-backdoor-paths" class="section level4">
<h4>1. Backdoor paths</h4>
<p><strong>Definition:</strong> A backdoor path between X and Y is a path that leaves through a parent of X and points to Y.</p>
<p>For example, the path <strong>icecream sales</strong> <span class="math inline">\(\leftarrow\)</span> <strong>sunshine</strong> <span class="math inline">\(\rightarrow\)</span> <strong>sunburn</strong> is a backdoor path between icecream sales and sunburn. <img src="draw-your-assumptions_files/figure-html/unnamed-chunk-15-1.png" width="624" /></p>
<p>You will recognise this as an example of confounding. In this case, the presence of sunshine induces a correlation or <em>dependence</em> between icecream and sunburn. The “d” in d-connected stands for <strong>dependence</strong>!</p>
</div>
<div id="section-open-paths" class="section level4">
<h4>2. Open paths</h4>
<p>A path between two nodes X and Y is open if the path carries information or dependence between X and Y. We can open or close a path between two nodes by controlling for an intermediate variables. In most contexts, conditioning will mean stratifying by a variable or adding the variable to a regression model.</p>
<p>Importantly, however, whether or not controlling for an intermediate variable Z opens the the pathway or closes the pathway depends on the role of Z. The table below outlines what happens in three different scenarios.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
DAG
</th>
<th style="text-align:left;">
Role of Z
</th>
<th style="text-align:left;">
Status before controlling for Z
</th>
<th style="text-align:left;">
Effect of controlling for Z
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 4cm; ">
<img src="/images/mediator-dag.png" style="width:80.0%" />
</td>
<td style="text-align:left;width: 2cm; ">
Mediator
</td>
<td style="text-align:left;width: 3cm; ">
Path between X and Y is OPEN
</td>
<td style="text-align:left;">
CLOSES path between X and Y.
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; ">
<img src="/images/confounder-dag.png" style="width:80.0%" />
</td>
<td style="text-align:left;width: 2cm; ">
Confounder
</td>
<td style="text-align:left;width: 3cm; ">
Path between X and Y is OPEN
</td>
<td style="text-align:left;">
CLOSES path between X and Y
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; ">
<img src="/images/collider-dag.png" style="width:80.0%" />
</td>
<td style="text-align:left;width: 2cm; ">
Collider
</td>
<td style="text-align:left;width: 3cm; ">
Path between X and Y is CLOSED
</td>
<td style="text-align:left;">
OPENS path between X and Y
</td>
</tr>
</tbody>
</table>
<p>Note that conditioning on a mediator or a confounder will CLOSE the path between X and Y. In the case of colliders, the path is closed unless we condition on Z in which case we OPEN the path between X and Y.</p>
</div>
<div id="section-how-does-this-all-help" class="section level3">
<h3>How does this all help?</h3>
<p>Having read through the section above, you should be comfortable with the idea of:</p>
<ol style="list-style-type: decimal">
<li>A backdoor path</li>
<li>An open or closed path</li>
</ol>
<p>Now, recall the definition of d-separation:</p>
<blockquote>
<p>Two variables in a DAG are said to be d-separated if there are no open backdoor paths between them</p>
</blockquote>
<div class="under-the-bonnet">
<h3 id="section-apply-the-concept-of-d-separation-to-inform-variable-selection-in-causal-models">Apply the concept of d-separation to inform variable selection in causal models</h3>
<p>In order to estimate the causal effect of an exposure X on an outcome Y, we have to make sure that X and Y are d-separated. That is, there can be no open backdoor paths between X and Y.</p>
</div>
</div>
</div>
<div id="section-quiz-1" class="section level2">
<h2>Quiz</h2>
</div>
<div id="section-selection-bias-1" class="section level2">
<h2>Selection Bias</h2>
</div>
<div id="section-quiz-2" class="section level2">
<h2>Quiz</h2>
</div>
<div id="section-m-bias" class="section level2">
<h2>M-Bias</h2>
<p>Tweetorial from Dr Ellie Murray (<span class="citation">[@EpiEllie]</span>(twitter.com/EpiEllie)) focuses on <strong>“applying conclusions about causation to results obtained via methods designed only for finding correlations”</strong>. This example shows a real-world example of M-bias in play, which erroneously led some to conclude that being a current smoker was protective of COVID-19 hospital deaths. Find it <a href="https://twitter.com/EpiEllie/status/1258607277357006849">here</a></p>
</div>
<div id="section-exercise" class="section level2">
<h2>Exercise</h2>
<p>Draw DAG consistent with two different hypotheses and estimate the corresponding model</p>
</div>
<div id="section-extra-coding-dags-in-r" class="section level2">
<h2>Extra: Coding DAGs in R</h2>
<div id="section-coding-dags-in-r-overview" class="section level3">
<h3>Coding DAGS in R: Overview</h3>
<p>The DAGs in this tutorial are created using the <code>ggdag</code> package. If you are interested in learning more about how to draw DAGs in this way, check out the vignette on the package <a href="https://cran.r-project.org/web/packages/ggdag/vignettes/intro-to-ggdag.html">here</a>.</p>
</div>
<div id="section-demonstration" class="section level3">
<h3>Demonstration</h3>
<p>Navigate through the slides below to see an example of <code>ggdag</code> in action.</p>
<iframe src="images/flipbook-ggdag.html" width="100%" height="400px">
</iframe>
<p>Note that:</p>
<ul>
<li>By default, the position of nodes is random. You can specify fixed node positions using <code>coords =</code>.</li>
<li>The funtion <code>dagify()</code> is used to define the relationships between nodes. E.g. <code>y ~ x</code> indicates that an arrow will point from <strong>x</strong> to <strong>y</strong>.<br />
</li>
<li>Passing the output of <code>dagify()</code> to <code>node_parents(x)</code> creates a dataframe distinguishing between child and parent nodes of <strong>x</strong>.</li>
<li><code>geom_dag_point()</code> and <code>geom_dag_edges()</code> plot the results.</li>
<li>Applying <code>theme_dag()</code> provides a nice clean plot.</li>
</ul>
</div>
<div id="section-try-it-yourself" class="section level3">
<h3>Try it yourself</h3>
<p>Try experimenting with the code below to create your own DAG.</p>
<div class="tutorial-exercise" data-label="ggdag1" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="25">
<pre class="text"><code># specifying fixed coordinates means that the nodes of the DAG will 
# always be in the same in the same place. If we don&#39;t include this, 
# the nodes will be randomly arranged each time the DAG is drawn
coords &lt;- list(
        x = c(x = 0, y = 1, a = 1, b = 0),
        y = c(x = 0, y = 1, a = 0, b = 1)
    )


dagify(y ~ x + a + b,
       x ~ a + b,
       exposure = &quot;x&quot;,
       outcome = &quot;y&quot;,
       coords = coords) %&gt;%  
  node_parents(&quot;x&quot;) %&gt;% 
  ggplot(aes(x=x, y=y, xend=xend, yend=yend, color=parent)) + 
  geom_dag_point() + 
  geom_dag_edges() +
  geom_dag_text(col = &quot;white&quot;, size = 6) + 
  geom_dag_edges_link(arrow = grid::arrow()) + 
  theme_dag() + 
  scale_color_hue(
    breaks  = c(&quot;parent&quot;, &quot;child&quot;)
    ) </code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<p>You might notice that this code differs slightly from the code in the flipbook slides above. The flipbook code uses <em>slow ggplot</em> as described by the <code>flipbookr</code> package developer Evangeline Reynolds in her <a href="https://evangelinereynolds.netlify.app/post/slow-ggplot/">blog</a>. Slow ggplot is an approach to writing ggplot code that focuses on incremental changes, for example, instead of specifying <code>aes(x=xy, y=y, xend=xend, yend=yend, color=parent)</code> in a single line, slow ggplot separates out each aesthetic element to a separate line, to emphasise how that element affects the graph. The editable code above dispenses with the slow ggplot syntax, and is more typical of how you will write R code in the wild.</p>
</div>
</div>
<div id="section-summary" class="section level2">
<h2>Summary</h2>

<script type="application/shiny-prerendered" data-context="server-start">
library(learnr)
library(tidyverse)
library(ggplot2)
library(dagitty)
library(ggdag)
library(ggpubr)
library(flipbookr)
library(kableExtra)
knitr::opts_chunk$set(echo = FALSE)


</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = list(id = "au.edu.unsw.cbdrh.hdat9700.directed.acyclic.graphs"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "quiz1-1", question = structure("<strong>Prediction<\u002fstrong> has traditionally been associated with which of the following disciplines? (Select all that apply)", html = TRUE, class = c("html", "character")), answers = list(structure(list(id = "lnr_ans_defe5a3",     option = "Finance", value = "Finance", label = structure("Finance", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_48b0bf",     option = "Psychology", value = "Psychology", label = structure("Psychology", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_c4a25ab",     option = "Bioinformatics", value = "Bioinformatics", label = structure("Bioinformatics", html = TRUE, class = c("html",     "character")), correct = TRUE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_c95c286",     option = "Education", value = "Education", label = structure("Education", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_d590108",     option = "Environmental science", value = "Environmental science",     label = structure("Environmental science", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_e6c4e84",     option = "Natural language processing", value = "Natural language processing",     label = structure("Natural language processing", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_86b2579",     option = "Microeconomics", value = "Microeconomics", label = structure("Microeconomics", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer"))), button_labels = list(submit = structure("Submit Answer", html = TRUE, class = c("html", "character")), try_again = structure("Try Again", html = TRUE, class = c("html", "character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", "character")), try_again = structure("Prediction is the domain of finance, bioinfomatics and natural language processing. The fields of psychology, education, environmental sciences and microeconnomics are primarily concerned with questions of a causal nature.", html = TRUE, class = c("html", "character")), incorrect = structure("Prediction is the domain of finance, bioinfomatics and natural language processing. The fields of psychology, education, environmental sciences and microeconnomics are primarily concerned with questions of a causal nature.", html = TRUE, class = c("html", "character")), message = NULL, post_message = NULL), ids = list(    answer = "quiz1-1-answer", question = "quiz1-1"), loading = structure("<strong>Loading:<\u002fstrong> \n<strong>Prediction<\u002fstrong> has traditionally been associated with which of the following disciplines? (Select all that apply)\n<br/><br/><br/>", html = TRUE, class = c("html", "character")), random_answer_order = FALSE, allow_retry = FALSE,     seed = 785380232.634279, options = list()), class = c("learnr_radio", "tutorial_question")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_checkbox", label = "quiz1-2", question = structure("Which modeling tasks are relevant to Health Data Science (Select all that apply)", html = TRUE, class = c("html", "character")), answers = list(structure(list(id = "lnr_ans_58b0e7",     option = "Description", value = "Description", label = structure("Description", html = TRUE, class = c("html",     "character")), correct = TRUE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_47b5bae",     option = "Prediction", value = "Prediction", label = structure("Prediction", html = TRUE, class = c("html",     "character")), correct = TRUE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_da6253f",     option = "Causal inference", value = "Causal inference",     label = structure("Causal inference", html = TRUE, class = c("html",     "character")), correct = TRUE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer"))), button_labels = list(submit = structure("Submit Answer", html = TRUE, class = c("html", "character")), try_again = structure("Try Again", html = TRUE, class = c("html", "character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", "character")), try_again = structure("All three tasks are relevant to a career in Health Data Science. Machine Learning I (HDAT9500) is primarily concerned with prediction. Topics in Statistical Modelling II (HDAT 9700) touch on description, prediction and causal inference. The important thing is choosing the most relevant approach for the research question.", html = TRUE, class = c("html", "character")), incorrect = structure("All three tasks are relevant to a career in Health Data Science. Machine Learning I (HDAT9500) is primarily concerned with prediction. Topics in Statistical Modelling II (HDAT 9700) touch on description, prediction and causal inference. The important thing is choosing the most relevant approach for the research question.", html = TRUE, class = c("html", "character")), message = NULL, post_message = NULL), ids = list(    answer = "quiz1-2-answer", question = "quiz1-2"), loading = structure("<strong>Loading:<\u002fstrong> \nWhich modeling tasks are relevant to Health Data Science (Select all that apply)\n<br/><br/><br/>", html = TRUE, class = c("html", "character")), random_answer_order = FALSE, allow_retry = FALSE,     seed = 851907284.6033, options = list()), class = c("learnr_checkbox", "tutorial_question")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "quiz2-1", question = structure("Which of the diagrams above is not a valid DAG?", html = TRUE, class = c("html", "character")), answers = list(structure(list(id = "lnr_ans_b4eeabf",     option = "A", value = "A", label = structure("A", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_dd7db7e",     option = "B", value = "B", label = structure("B", html = TRUE, class = c("html",     "character")), correct = TRUE, message = structure("Correct, (B) is not a valid DAG because it is not <em>directional<\u002fem>. This DAG would suggest that <strong>X<\u002fstrong> causes <strong>Y<\u002fstrong> and <strong>Y<\u002fstrong> causes <strong>X<\u002fstrong>.", html = TRUE, class = c("html",     "character"))), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_dc2203e", option = "C", value = "C",     label = structure("C", html = TRUE, class = c("html", "character"    )), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer"))), button_labels = list(submit = structure("Submit Answer", html = TRUE, class = c("html", "character")), try_again = structure("Try Again", html = TRUE, class = c("html", "character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", "character")), try_again = structure("This is a valid DAG, try again!", html = TRUE, class = c("html", "character")), incorrect = structure("This is a valid DAG, try again!", html = TRUE, class = c("html", "character")), message = NULL, post_message = NULL), ids = list(    answer = "quiz2-1-answer", question = "quiz2-1"), loading = structure("<strong>Loading:<\u002fstrong> \nWhich of the diagrams above is not a valid DAG?\n<br/><br/><br/>", html = TRUE, class = c("html", "character")), random_answer_order = FALSE, allow_retry = TRUE,     seed = 37137332.4827066, options = list()), class = c("learnr_radio", "tutorial_question")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "quiz3-1", question = structure("Which of the following statements matches the DAG above?", html = TRUE, class = c("html", "character")), answers = list(structure(list(id = "lnr_ans_a3436b8",     option = "Maternal age confounds the relationship between social deprivation and low birth weight.",     value = "Maternal age confounds the relationship between social deprivation and low birth weight.",     label = structure("Maternal age confounds the relationship between social deprivation and low birth weight.", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_cc33d90",     option = "Low birthweight confounds the relationship between social deprivation and maternal age.",     value = "Low birthweight confounds the relationship between social deprivation and maternal age.",     label = structure("Low birthweight confounds the relationship between social deprivation and maternal age.", html = TRUE, class = c("html",     "character")), correct = FALSE, message = NULL), class = c("tutorial_question_answer", "tutorial_quiz_answer")), structure(list(id = "lnr_ans_eeb4e5f",     option = "Social deprivation confounds the relationship between maternal age and low birthweight",     value = "Social deprivation confounds the relationship between maternal age and low birthweight",     label = structure("Social deprivation confounds the relationship between maternal age and low birthweight", html = TRUE, class = c("html",     "character")), correct = TRUE, message = structure("Correct. This DAG suggests that social deprivation is a common cause of maternal age and low birthweight", html = TRUE, class = c("html",     "character"))), class = c("tutorial_question_answer", "tutorial_quiz_answer"))), button_labels = list(submit = structure("Submit Answer", html = TRUE, class = c("html", "character")), try_again = structure("Try Again", html = TRUE, class = c("html", "character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", "character")), try_again = structure("Not quite right, try again!", html = TRUE, class = c("html", "character")), incorrect = structure("Not quite right, try again!", html = TRUE, class = c("html", "character")), message = NULL, post_message = NULL), ids = list(    answer = "quiz3-1-answer", question = "quiz3-1"), loading = structure("<strong>Loading:<\u002fstrong> \nWhich of the following statements matches the DAG above?\n<br/><br/><br/>", html = TRUE, class = c("html", "character")), random_answer_order = FALSE, allow_retry = TRUE,     seed = 475233478.778702, options = list()), class = c("learnr_radio", "tutorial_question")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ggdag1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ggdag1-code-editor`)), session)
output$`tutorial-exercise-ggdag1-output` <- renderUI({
  `tutorial-exercise-ggdag1-result`()
})
</script>
 <!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.10.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.10.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["kePrint"]},{"type":"character","attributes":{},"value":["0.0.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["kePrint-0.0.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["kePrint.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["kableExtra"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.1.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["kePrint"]},{"type":"character","attributes":{},"value":["0.0.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["kePrint-0.0.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["kePrint.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["kableExtra"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.1.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.0"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.0"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105]}},"value":[{"type":"character","attributes":{},"value":["assertthat","backports","base","boot","broom","cellranger","checkmate","cli","colorspace","compiler","cowplot","crayon","curl","dagitty","datasets","DBI","dbplyr","digest","dplyr","ellipsis","evaluate","fansi","farver","fastmap","flipbookr","forcats","fs","generics","ggdag","ggforce","ggplot2","ggpubr","ggraph","ggrepel","ggsignif","glue","graphics","graphlayouts","grDevices","grid","gridExtra","gtable","haven","highr","hms","htmltools","htmlwidgets","httpuv","httr","igraph","jsonlite","kableExtra","knitr","labeling","later","lattice","learnr","lifecycle","lubridate","magrittr","markdown","MASS","methods","mime","modelr","munsell","nlme","pillar","pkgconfig","polyclip","promises","purrr","R6","Rcpp","readr","readxl","reprex","rlang","rmarkdown","rprojroot","rstudioapi","rvest","scales","shiny","stats","stringi","stringr","tibble","tidygraph","tidyr","tidyselect","tidyverse","tools","tweenr","utils","V8","vctrs","viridis","viridisLite","webshot","withr","xfun","xml2","xtable","yaml"]},{"type":"character","attributes":{},"value":["0.2.1","1.1.8","3.6.1","1.3-23","0.5.3","1.1.0","2.0.0","2.0.2","1.4-1","3.6.1","1.0.0","1.3.4","4.3","0.2-2","3.6.1","1.1.0","1.4.2","0.6.25","0.8.5","0.3.1","0.14","0.4.1","2.0.3","1.0.1","0.1.0","0.4.0","1.3.1","0.0.2","0.2.2","0.3.1","3.3.2","0.2.3","2.0.1","0.8.2","0.6.0","1.4.1","3.6.1","0.5.0","3.6.1","3.6.1","2.3","0.3.0","2.2.0","0.8","0.5.3","0.4.0","1.5.1","1.5.2","1.4.1","1.2.5","1.7.0","1.1.0","1.26","0.3","1.0.0","0.20-38","0.10.0","0.2.0","1.7.8","1.5","1.1","7.3-51.4","3.6.1","0.9","0.1.5","0.5.0","3.1-143","1.4.6","2.0.3","1.10-0","1.1.0","0.3.4","2.4.1","1.0.5","1.3.1","1.3.1","0.3.0","0.4.7","2.0","1.3-2","0.11","0.3.5","1.1.1","1.4.0.2","3.6.1","1.4.6","1.4.0","3.0.3","1.1.2","1.0.3","1.1.0","1.3.0","3.6.1","1.0.1","3.6.1","3.2.0","0.3.2","0.5.1","0.3.0","0.5.2","2.2.0","0.12","1.2.2","1.8-4","2.2.1"]}]}]}
</script>
<!--/html_preserve-->
</div>

</div> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h2 class="title toc-ignore" style="display:none;">HDAT9700: Directed Acyclic Graphs (DAGs)</h2>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</div> <!-- bandContent page -->
</div> <!-- pageContent band -->




<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
